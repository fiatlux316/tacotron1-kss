{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D:\\DEV\\AI\\AISchool\\project\\multi-Speaker-tacotron-tensorflow\\audio\\silence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import librosa\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from pydub import silence\n",
    "from pydub import AudioSegment\n",
    "from functools import partial\n",
    "\n",
    "from hparams import hparams\n",
    "from utils import parallel_run, add_postfix\n",
    "from audio import load_audio, save_audio, get_duration, get_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_mean(x):\n",
    "    return abs(x).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_breath(audio):\n",
    "    edges = librosa.effects.split(\n",
    "            audio, top_db=40, frame_length=128, hop_length=32)\n",
    "\n",
    "    for idx in range(len(edges)):\n",
    "        start_idx, end_idx = edges[idx][0], edges[idx][1]\n",
    "        if start_idx < len(audio):\n",
    "            if abs_mean(audio[start_idx:end_idx]) < abs_mean(audio) - 0.05:\n",
    "                audio[start_idx:end_idx] = 0\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_silence_with_librosa(\n",
    "        audio_path, top_db=40, frame_length=1024, hop_length=256,\n",
    "        skip_idx=0, out_ext=\"wav\",\n",
    "        min_segment_length=3, max_segment_length=8,\n",
    "        pre_silence_length=0, post_silence_length=0):\n",
    "\n",
    "    filename = os.path.basename(audio_path).split('.', 1)[0]\n",
    "    in_ext = audio_path.rsplit(\".\")[1]\n",
    "\n",
    "    audio = load_audio(audio_path)\n",
    "\n",
    "    edges = librosa.effects.split(audio,\n",
    "            top_db=top_db, frame_length=frame_length, hop_length=hop_length)\n",
    "\n",
    "    new_audio = np.zeros_like(audio)\n",
    "    for idx, (start, end) in enumerate(edges[skip_idx:]):\n",
    "        new_audio[start:end] = remove_breath(audio[start:end])\n",
    "        \n",
    "    save_audio(new_audio, add_postfix(audio_path, \"no_breath\"))\n",
    "    audio = new_audio\n",
    "    edges = librosa.effects.split(audio,\n",
    "            top_db=top_db, frame_length=frame_length, hop_length=hop_length)\n",
    "\n",
    "    audio_paths = []\n",
    "    for idx, (start, end) in enumerate(edges[skip_idx:]):\n",
    "        segment = audio[start:end]\n",
    "        duration = get_duration(segment)\n",
    "\n",
    "        if duration <= min_segment_length or duration >= max_segment_length:\n",
    "            continue\n",
    "\n",
    "        output_path = \"{}/{}.{:04d}.{}\".format(\n",
    "                os.path.dirname(audio_path), filename, idx, out_ext)\n",
    "\n",
    "        padded_segment = np.concatenate([\n",
    "                get_silence(pre_silence_length),\n",
    "                segment,\n",
    "                get_silence(post_silence_length),\n",
    "        ])\n",
    "\n",
    "\n",
    "        \n",
    "        save_audio(padded_segment, output_path)\n",
    "        audio_paths.append(output_path)\n",
    "\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_audio(audio_path):\n",
    "    return AudioSegment.from_file(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_silence_with_pydub(\n",
    "        audio_path, skip_idx=0, out_ext=\"wav\",\n",
    "        silence_thresh=-40, min_silence_len=400,\n",
    "        silence_chunk_len=100, keep_silence=100):\n",
    "\n",
    "    filename = os.path.basename(audio_path).split('.', 1)[0]\n",
    "    in_ext = audio_path.rsplit(\".\")[1]\n",
    "\n",
    "    audio = read_audio(audio_path)\n",
    "    not_silence_ranges = silence.detect_nonsilent(\n",
    "        audio, min_silence_len=silence_chunk_len,\n",
    "        silence_thresh=silence_thresh)\n",
    "\n",
    "    edges = [not_silence_ranges[0]]\n",
    "\n",
    "    for idx in range(1, len(not_silence_ranges)-1):\n",
    "        cur_start = not_silence_ranges[idx][0]\n",
    "        prev_end = edges[-1][1]\n",
    "\n",
    "        if cur_start - prev_end < min_silence_len:\n",
    "            edges[-1][1] = not_silence_ranges[idx][1]\n",
    "        else:\n",
    "            edges.append(not_silence_ranges[idx])\n",
    "    \n",
    "    audio_paths = []\n",
    "    for idx, (start_idx, end_idx) in enumerate(edges[skip_idx:]):\n",
    "        start_idx = max(0, start_idx - keep_silence)\n",
    "        end_idx += keep_silence\n",
    "\n",
    "        target_audio_path = \"{}/{}.{:04d}.{}\".format(\n",
    "                os.path.dirname(audio_path), filename, idx, out_ext)\n",
    "\n",
    "        segment=audio[start_idx:end_idx]\n",
    "        \n",
    "        segment.export(target_audio_path, out_ext)  # for soundsegment\n",
    "\n",
    "        audio_paths.append(target_audio_path)\n",
    "\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_on_silence_batch(audio_paths, method, **kargv):\n",
    "    audio_paths.sort()\n",
    "    method = method.lower()\n",
    "\n",
    "    if method == \"librosa\":\n",
    "        fn = partial(split_on_silence_with_librosa, **kargv)\n",
    "    elif method == \"pydub\":\n",
    "        fn = partial(split_on_silence_with_pydub, **kargv)\n",
    "\n",
    "    parallel_run(fn, audio_paths,\n",
    "            desc=\"Split on silence\", parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m audio.silence --audio_pattern \"./datasets/son/audio/*.wav\" --method=pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--method=pydub'], dest='method=pydub', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #parser.add_argument('--audio_pattern', required=True)\n",
    "    #parser.add_argument('--out_ext', default='wav')\n",
    "    #parser.add_argument('--method', choices=['librosa', 'pydub'], required=True)\n",
    "    \n",
    "    parser.add_argument('--audio_pattern ./datasets/son/audio/*.wav')\n",
    "    #parser.add_argument('--out_ext', default='wav')\n",
    "    parser.add_argument('--method=pydub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --audio_pattern AUDIO_PATTERN\n",
      "                             [--out_ext OUT_EXT] --method {librosa,pydub}\n",
      "                             [--audio_pattern=./datasets/son/audio/*.wav AUDIO_PATTERN=./DATASETS/SON/AUDIO/*.WAV]\n",
      "                             [--audio_pattern ./datasets/son/audio/*.wav AUDIO_PATTERN ./DATASETS/SON/AUDIO/*.WAV]\n",
      "                             [--method=pydub METHOD=PYDUB]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --audio_pattern, --method\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DEV\\Engineering\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "config = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split on silence: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "    split_on_silence_batch(glob('./datasets/son/audio/*.wav'), 'pydub')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
